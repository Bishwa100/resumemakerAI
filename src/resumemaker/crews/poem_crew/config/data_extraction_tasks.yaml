extract_linkedin_data:
  description: >
    Scrape the LinkedIn profile at {{ linkedin_url }} using BeautifulSoup and Scrapy to gather candidate skills, 
    endorsements, job history, and other relevant professional details, ensuring all publicly available data is captured.
  expected_output: >
    A structured JSON dataset containing LinkedIn profile information, including skills (e.g., listed skills, endorsements), 
    experience (e.g., job titles, companies, durations),education (e.g., degrees, institutions) and add all things which help to build the resume.
  

extract_github_data:
  description: >
    Fetch data from the GitHub profile at {{ github_url }} using the GitHub API via requests and Scrapy to collect 
    repositories, contributions, programming languages used, and project descriptions to assess technical skills.
  expected_output: >
    A structured JSON summary of GitHub activities, including active repositories (e.g., names, descriptions), 
    technologies used (e.g., languages, frameworks), and code contributions (e.g., commits, pull requests).
  

analyze_job_posting:
  description: >
    Analyze the job description provided at {{ job_posting }} (URL or raw text) using BeautifulSoup for web scraping 
    and pdfplumber for PDFs to extract key requirements, skills, experience levels, and industry-relevant keywords.
  expected_output: >
    A structured JSON breakdown of the job posting, highlighting required skills (e.g., technical, soft), experience 
    levels (e.g., years required), and essential keywords (e.g., industry jargon, tools).
  

compare_resume_with_job:
  description: >
    Match the extracted resume data ({{ resume_data }}) with the job requirements ({{ job_requirements }}) using text 
    analysis to assess alignment, identify gaps, and suggest improvements for better job fit.
  expected_output: >
    A structured JSON comparison report detailing how well the resume aligns with the job requirements (e.g., matching 
    skills, experience overlap) and suggesting areas for improvement (e.g., missing skills, keywords).
  

structure_candidate_profile:
  description: >
    Organize the extracted data from resumes ({{ resume_data }}), LinkedIn ({{ linkedin_data }}), and GitHub 
    ({{ github_data }}) into a cohesive, structured candidate profile using Pandas, highlighting strengths and job relevance.dditionally, save the structured profile into a Retrieval-Augmented Generation (RAG) database for future queries.
  expected_output: >
    A well-structured JSON candidate profile combining resume, LinkedIn, and GitHub data, ready for optimization or storage 
    in a database, including sections like experience, education, skills, projects and more all the relevent things.
  