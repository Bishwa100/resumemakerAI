extract_resume_data:
  description: >
    Extract text from the uploaded resume file at {{ resume_file }} (PDF or DOCX format) using PyPDF2 for text-based files 
    and pytesseract for image-based files, then structure the extracted data into relevant sections such as experience, 
    education, and skills.
  expected_output: >
    A structured JSON representation of resume data, including job history (e.g., title, company, dates), education 
    (e.g., degree, institution), and skills (e.g., technical, soft skills).
  agent: data_extraction_agent

extract_linkedin_data:
  description: >
    Scrape the LinkedIn profile at {{ linkedin_url }} using BeautifulSoup and Scrapy to gather candidate skills, 
    endorsements, job history, and other relevant professional details, ensuring all publicly available data is captured.
  expected_output: >
    A structured JSON dataset containing LinkedIn profile information, including skills (e.g., listed skills, endorsements), 
    experience (e.g., job titles, companies, durations), and education (e.g., degrees, institutions).
  agent: data_extraction_agent

extract_github_data:
  description: >
    Fetch data from the GitHub profile at {{ github_url }} using the GitHub API via requests and Scrapy to collect 
    repositories, contributions, programming languages used, and project descriptions to assess technical skills.
  expected_output: >
    A structured JSON summary of GitHub activities, including active repositories (e.g., names, descriptions), 
    technologies used (e.g., languages, frameworks), and code contributions (e.g., commits, pull requests).
  agent: data_extraction_agent

analyze_job_posting:
  description: >
    Analyze the job description provided at {{ job_posting }} (URL or raw text) using BeautifulSoup for web scraping 
    and pdfplumber for PDFs to extract key requirements, skills, experience levels, and industry-relevant keywords.
  expected_output: >
    A structured JSON breakdown of the job posting, highlighting required skills (e.g., technical, soft), experience 
    levels (e.g., years required), and essential keywords (e.g., industry jargon, tools).
  agent: job_analysis_agent

compare_resume_with_job:
  description: >
    Match the extracted resume data ({{ resume_data }}) with the job requirements ({{ job_requirements }}) using text 
    analysis to assess alignment, identify gaps, and suggest improvements for better job fit.
  expected_output: >
    A structured JSON comparison report detailing how well the resume aligns with the job requirements (e.g., matching 
    skills, experience overlap) and suggesting areas for improvement (e.g., missing skills, keywords).
  agent: job_analysis_agent

structure_candidate_profile:
  description: >
    Organize the extracted data from resumes ({{ resume_data }}), LinkedIn ({{ linkedin_data }}), and GitHub 
    ({{ github_data }}) into a cohesive, structured candidate profile using Pandas, highlighting strengths and job relevance.
  expected_output: >
    A well-structured JSON candidate profile combining resume, LinkedIn, and GitHub data, ready for optimization or storage 
    in a database, including sections like experience, education, skills, and projects.
  agent: profile_structuring_agent